<h1>prototypical networks for few-shot learning</h1>
<h2>few-shot classification</h2>
<p>few-shot classification is a task to train a classifier which can classify example among classes not seen in training with only few labeled examples of each class.</p>
<h3>N-way K-shot classification</h3>
<ul>
<li>input: $S^1, \cdots, S^N, Q$
<ul>
<li>$S^n = { \mathbb{s}^n_1, \cdots, \mathbb{s}^n_K }, n \in {1, \cdots, N}$: class $n$ support set (examples with class $n$)</li>
<li>$Q = { \mathbb{q}_1, \cdots, \mathbb{q}_M }$: query set (examples to predict class)</li>
</ul>
</li>
<li>output: $P$
<ul>
<li>$P = { \mathbb{p}_1, \cdots, \mathbb{p}_M }$: predicted class probabilities</li>
</ul>
</li>
</ul>
<h2>model</h2>
<h3>structure</h3>
<ul>
<li>$f_\theta(\cdot)$: embedding function</li>
<li>$D(\cdot, \cdot)$: distance function</li>
</ul>
<p>prediction</p>
<ol>
<li><strong>for</strong> $n$ <strong>in</strong> ${ 1, \cdots, N }$ <strong>do</strong>
<ol>
<li>$\mathbb{c}^n \leftarrow \frac{1}{N} \sum\limits_{\mathbb{s} \in S^n} f_\theta(\mathbb{s})$</li>
</ol>
</li>
<li><strong>for</strong> $m$ <strong>in</strong> ${ 1, \cdots, M }$ <strong>do</strong>
<ol>
<li>$\mathbb{e}<em>m \leftarrow f</em>\theta(\mathbb{q}_m)$</li>
<li>$\mathbb{d}_m \leftarrow \left( D(\mathbb{e}_m, \mathbb{c}^1), \cdots, D(\mathbb{e}_m, \mathbb{c}^N) \right)$</li>
<li>$\mathbb{p}_m \leftarrow \text{softmin}(\mathbb{d}_m)$</li>
</ol>
</li>
</ol>
<h3>train</h3>
<ul>
<li>$N_C$: # way</li>
<li>$N_S$: # shot</li>
<li>$N_Q$: # query per way</li>
<li>loss function: negative log-probability of true class</li>
<li>train set: $T^1, \cdots, T^U$
<ul>
<li>$T^u = { \mathbb{x}^u_1, \cdots, \mathbb{x}^u_V }, u \in { 1, \cdots, U }$: $V$ examples with class $u$</li>
</ul>
</li>
</ul>
<p>train is done by iterating over episodes.</p>
<p>train episode</p>
<ol>
<li>$u_1, \cdots, u_{N_C} \leftarrow \text{RandomSample}({ 1, \cdots, U }, N_C)$</li>
<li><strong>for</strong> $i$ <strong>in</strong> ${ 1, \cdots, N_C }$ <strong>do</strong>
<ol>
<li>$S^{u_i} = (\mathbb{s}^{u_i}<em>1, \cdots, \mathbb{s}^{u_i}</em>{N_S}) \leftarrow \text{RandomSample}(T^{u_i}, N_S)$</li>
<li>$Q^{u_i} = (\mathbb{q}^{u_i}<em>1, \cdots, \mathbb{q}^{u_i}</em>{N_Q}) \leftarrow \text{RandomSample}(T^{u_i} \backslash S^{u_i}, N_Q)$</li>
<li>$\mathbb{c}^{u_i} \leftarrow \frac{1}{N_C} \sum\limits_{\mathbb{s} \in S^{u_i}} f_\theta(\mathbb{s})$</li>
</ol>
</li>
<li><strong>for</strong> $i$ <strong>in</strong> ${ 1, \cdots, N_C }$ <strong>do</strong>
<ol>
<li><strong>for</strong> $j$ <strong>in</strong> ${ 1, \cdots, N_Q }$ <strong>do</strong>
<ol>
<li>$\mathbb{e}^{u_i}<em>j \leftarrow f</em>\theta(\mathbb{q}^{u_i}_j)$</li>
<li>$\mathbb{d}^{u_i}_j \leftarrow \left( D(\mathbb{e}^{u_i}_j, \mathbb{c}^{u_1}), \cdots, D(\mathbb{e}^{u_i}<em>j, \mathbb{c}^{u</em>{N_C}}) \right)$</li>
<li>$\mathbb{p}^{u_i}_j \leftarrow \text{softmin}(\mathbb{d}^{u_i}_j)$</li>
<li>$\mathcal{J}^{u_i}<em>j \leftarrow \ln \mathbb{p}^{u_i}</em>{j, i}$</li>
</ol>
</li>
</ol>
</li>
<li>$\mathcal{J} \leftarrow \frac{1}{N_C N_Q} \sum\limits^{N_C}<em>{i = 1} \sum\limits^{N_Q}</em>{j = 1} \mathcal{J}^{u_i}_j$</li>
<li>update $\phi$ based on cost $\mathcal{J}$</li>
</ol>
